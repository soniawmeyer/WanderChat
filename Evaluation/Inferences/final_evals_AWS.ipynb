{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from langchain_community.llms import Ollama\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # import hf embedding\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://stombfggw2li7usf.us-east-1.aws.endpoints.huggingface.cloud'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_token = os.getenv(\"hf_token\")\n",
    "llama_qlora = os.getenv(\"llama_qlora_api\")\n",
    "llama_raft = os.getenv(\"llama_raft_api\")\n",
    "mistral_qlora = os.getenv(\"mistral_qlora_api\")\n",
    "mistral_raft = os.getenv(\"mistral_raft_api\")\n",
    "\n",
    "llama_qlora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "headers = {\n",
    "\t\"Accept\" : \"application/json\",\n",
    "\t\"Authorization\": f\"Bearer {hf_token}\",\n",
    "\t\"Content-Type\": \"application/json\" \n",
    "}\n",
    "\n",
    "model_dict = {'pretrained Llama':\"\", #https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
    "              'pretrained Mistral':\"\", #https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2\n",
    "              'Llama QLORA':llama_qlora, #https://huggingface.co/beraht/llama-2-7b_qlora_falcon_417\n",
    "              'Llama RAFT':llama_raft, #https://huggingface.co/beraht/Llama2_Falcon_RAFT_50e_10s/tree/main\n",
    "              'Mistral QLORA':mistral_qlora, #https://huggingface.co/sherrys/mistral-2-7b_qlora_falcon_426/tree/main\n",
    "              'Mistral RAFT':mistral_raft #https://huggingface.co/sherrys/426_mistral_RAFT_50e_10s\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://stombfggw2li7usf.us-east-1.aws.endpoints.huggingface.cloud'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_URL = model_dict.get('Llama QLORA')\n",
    "API_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query(payload):\n",
    "  response = requests.post(API_URL, headers=headers, json=payload)\n",
    "  return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Notes', 'Golden Question', 'Golden Answer', 'MPC',\n",
       "       'Llama QLORA Output', 'Llama QLORA Output Time',\n",
       "       'pretrained Mistral Output', 'pretrained Mistral Output Time',\n",
       "       'Mistral QLORA Output', 'Mistral QLORA Output Time',\n",
       "       'Llama RAFT Output', 'Llama RAFT Output Time', 'Mistral RAFT Output',\n",
       "       'Mistral RAFT Output Time', 'pretrained Llama Output',\n",
       "       'pretrained Llama Output Time', 'Llama_RAG_CRC', 'Llama_RAG_CRC_time',\n",
       "       'mistral_RAG_CRC', 'mistral_RAG_CRC_time', 'mistral_RAG_RR',\n",
       "       'mistral_RAG_RR_time', 'llama_RAG_RR', 'llama_RAG_RR_time',\n",
       "       'Llama RAFT RAG CRC Output', 'Llama RAFT RAG CRC Output Time',\n",
       "       'Mistral RAFT RAG CRC GPT prompt summary Output',\n",
       "       'Mistral RAFT RAG CRC GPT prompt summary Output Time',\n",
       "       'Mistral QLORA RAG CRC GPT prompt summary Output',\n",
       "       'Mistral QLORA RAG CRC GPT prompt summary Output Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_evals = pd.read_csv(\"inferences_5_2.csv\",index_col=\"Unnamed: 0\")\n",
    "raw_evals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_model = SentenceTransformer('sentence-transformers/multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "def augment_prompt(query: str,source_knowledge:str):\n",
    "    return f'''Using the contexts below, answer the question as if you are a travel agent and your goal is to provide excellent customer service and to provide\n",
    "            personalized travel recommendations with reasonings based on their question. Do not repeat yourself or include any links or HTML. Say \"I don't know\" if you\n",
    "            are uncertain.\n",
    "            Contexts:\n",
    "            {source_knowledge}\n",
    "\n",
    "            Query: {query}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local(\"../vector_db/funcheap_2024-04-26_2024-06-25_db\",\n",
    "                      HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', model_kwargs={'device': 'cpu'})).as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/posts/andrewrreed/656761313696494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are your favorite luxury camp meals for a beginner-friendly 10-mile, 3-day backpacking trip, considering I'm willing to carry 10lbs of food and have basic cookware?\n",
      "441\n",
      "Failed to process prompt with token length: 859\n",
      "Failed to process prompt with token length: 759\n",
      "Failed to process prompt with token length: 659\n",
      "Failed to process prompt with token length: 559\n",
      "Failed to process prompt with token length: 459\n",
      "Failed to process prompt with token length: 359\n",
      "Failed to process prompt with token length: 259\n",
      "Failed to process prompt with token length: 159\n",
      "Failed to process prompt with token length: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:03, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process prompt with token length: -41\n",
      "{'error': 'Input validation error: `inputs` must have less than 1024 tokens. Given: 1126', 'error_type': 'validation'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m duration \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n\u001b[0;32m---> 26\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43manswer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<s>[INST] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [/INST]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m answer \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m . \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     29\u001b[0m raw_evals\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMistral  RAG CRC Output\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m answer\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for i,r in tqdm(raw_evals.iterrows()):\n",
    "    start = time.time()\n",
    "    q = r['Golden Question']\n",
    "    print(q)\n",
    "    rag_contexts = db.invoke(q)\n",
    "    rag_contexts = ' '.join([d.page_content for d in rag_contexts])\n",
    "    prompt = augment_prompt(q,rag_contexts)\n",
    "    input_len = len(prompt.split())\n",
    "    print(input_len)\n",
    "    max_token_len = 1500-input_len-100 #100 buffer\n",
    "    start_time = time.time()\n",
    "    while True: #while loop for token\n",
    "        answer = query({'inputs': f\"<s>[INST] {prompt} [/INST]\",\n",
    "                    'parameters': {\"max_new_tokens\": max_token_len}})\n",
    "        if 'error' not in answer:\n",
    "            break  #exit the while loop if there is no error\n",
    "        max_token_len -= 100 #reduce by 100 in while loop\n",
    "        print(f\"Failed to process prompt with token length: {max_token_len}\")\n",
    "        if max_token_len <= 0:\n",
    "            break\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(answer)\n",
    "    \n",
    "    answer = answer[0]['generated_text'].replace(f\"<s>[INST] {prompt} [/INST]\",\"\")\n",
    "    answer = answer.replace(\" . \",\". \").strip()\n",
    "\n",
    "    raw_evals.loc[i,'Mistral  RAG CRC Output'] = answer\n",
    "    raw_evals.loc[i,'Mistral RAFT RAG CRC Output Time'] =  time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def generate_response(question):\n",
    "    msg = [{\"role\": \"user\",\"content\": question,}]\n",
    "    res = client.chat.completions.create(messages=msg,model=\"gpt-3.5-turbo\",temperature=0,)\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are your favorite luxury camp meals for a beginner-friendly 10-mile, 3-day backpacking trip, considering I'm willing to carry 10lbs of food and have basic cookware?\n",
      "169 2706 277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:31, 31.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm taking a solo trip with my dog around Thanksgiving. I understand some National Parks only let you take dogs in specific areas. I have about 10 days and could potentially extend 1-2 days if necessary. Any suggestions or considerations?\n",
      " \n",
      " Plan:\n",
      " Day 1 - drive 10-12 hours (sleep at rest stops)\n",
      " Day 2 - drive 10-12 hours and reach Albuquerque\n",
      " Day 3 - Monument Valley\n",
      " Day 4 - Capital Reef to Bryce, stay in Hatch\n",
      " Day 5 - Grand Canyon, stay in Sedona\n",
      " Day 6 - Phoenix\n",
      " Day 7 - White Sand Dunes and Carlsbad Caverns\n",
      " Day 8 - Fort Worth, eat at Goldee's BBQ\n",
      " Day 9 - drive 10-12 hours home\n",
      "591 3070 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:02, 31.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm planning a 3-4 week family road trip from Vancouver to Quebec and then Nova Scotia this summer, aiming to make it an unforgettable cross-Canada adventure for my teenagers before they grow up. We're considering driving through the US via I90 to check out attractions like Yellowstone, and returning through Canada, balancing our stay between camping, hotels (50%), and family friends. We'd appreciate any advice on what to consider and places to explore along this route.\n",
      "474 2986 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [01:36, 32.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the main differences between visiting Seoul and Tokyo regarding cost, public transit, weather, food, foreigner friendliness, people, and nightlife based on personal experiences?\n",
      "186 3000 542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:12, 33.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeking destination and activity suggestions for a first solo trip over my birthday weekend. I'm from Kalamazoo, MI, and can travel for 3-4 nights at the end of March. Looking for nature, hiking, possibly beach locations, plus nightlife, museums, good food, and botanical gardens. Willing to fly and rent a car, aiming for straightforward, not too lengthy travel, and budget-friendly options. Any advice?\n",
      "404 3354 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [02:42, 32.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where's the best place to go \"monk mode\" for three months to focus on a project? I'm seeking a quiet neighborhood with the option to rent a pleasant living space. Additionally, access to fresh, affordable produce and a form of physical activity (other than hiking) for breaks would be ideal.\n",
      "291 2810 346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [03:14, 32.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a 28-year-old male heading to Guangzhou for the first time this December for a three-week stay. Without Mandarin or Cantonese skills, I'm looking for advice on engaging activities and places to explore. My interests include spas, nightlife, good food, video games, anime, and technology. Since post-Covid information seems scarce, could you recommend what to do, see, or learn? I'll be with my significant other and in-laws, seeking to make the most of this trip both together and on my own.\n",
      "495 3199 485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [03:47, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Ho Chi Minh safe for a girl's solo trip?\n",
      "43 2508 373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [04:20, 32.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm considering booking a trip through Costco Travel and am curious about others' experiences and costs. What destinations have you visited with Costco packages, how long was your trip, and what was included? Did you find these packages provided good value for money, and would you recommend them for a specific type of traveler?\n",
      "329 2867 412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [04:51, 32.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm planning a two-month trip to Europe in May and June and am looking for recommendations on cities or regions that are hidden gems, beyond the well-known tourist attractions. Given the overwhelming amount of amazing suggestions, I'm even considering extending my trip by a month. What unique places do you recommend?\n",
      "318 3120 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [05:24, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to take a cruise to Alaska in August and want to sail from San Francisco. I'll be traveling with my husband and toddler. There are so many options though, how do I know which itinerary to pick? I guess, what are the typical ports? Pros/cons? Which are must sees?\n",
      "269 3222 325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [05:55, 31.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the current travel restrictions to Japan?\n",
      "50 2487 426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [06:28, 32.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you have tips for finding a cheap flight from New York to Paris for next month?\n",
      "82 2417 244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [07:02, 32.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the baggage allowance for my flight to Brazil?\n",
      "54 2795 566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [07:34, 32.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any good hotel deals in Rome for the summer?\n",
      "54 1955 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [08:10, 33.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I need a visa to visit Australia for a week?\n",
      "47 2305 305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [08:43, 33.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How do I change my flight reservation?\n",
      "38 2568 308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [09:16, 33.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the top attractions in New York City?\n",
      "46 2924 288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [09:50, 33.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you recommend a family-friendly resort in Florida?\n",
      "54 2916 212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [10:24, 33.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the best way to get around in Tokyo?\n",
      "44 2548 377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [10:57, 33.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My college roommate is getting married in Israel next month, and I would like to attend her wedding, but Is it safe to visit Israel right now?\n",
      "142 2281 241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [11:31, 33.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i go to san jose state. where can i grab some cheap eats in between classes?\n",
      "76 2613 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [12:04, 33.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'd like to visit stanford this weekend. can you help me plan my trip. how can i get there? i live in san jose. are there any events that i can attend. and also any good food place?\n",
      "181 2734 503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [12:37, 33.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm planning to visit a friend in berkeley. what would be the most affordable way to get there from my place in san jose\n",
      "120 2638 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [13:11, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are there any good places for me and my friends to hang out in bay area. we are both foodies and asians\n",
      "103 3053 238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [13:42, 32.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm a berkeley student who just started my french learning this semseter. are there any events nearby that i can attend that's both fun and educational?\n",
      "152 2721 266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [14:14, 32.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a super movie fan. and i know that san francisco has a movie festival this weekend. help me plan a day so that i can use up my time most efficiently.\n",
      "154 2522 299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [14:47, 32.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i live in san jose and i love hiking. any good recommendations for a weekend hike with friends and my dog\n",
      "105 2687 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [15:24, 34.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm visiting Oakland in May and heard about a unique event called HellaSecret Comedy & Cocktail Night. Can you tell me how I can attend this event and what to expect?\n",
      "166 2885 301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29it [15:54, 32.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where can I take my mother for window shopping and to see a local market in San Francisco on Sunday, May 12?\n",
      "108 2924 239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [16:28, 32.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My friends are visiting California in June and heard about a Free National Parks Day. Can you tell me when this occurs and if it includes popular parks like Muir Woods and Yosemite?\n",
      "181 2654 291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [17:01, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I bring my dog to just watch the events at the 17th Annual DogFest without participating in the competitions, and what things would be there to see?\n",
      "\n",
      "\n",
      "154 2611 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [17:34, 33.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any comedy shows in San Francisco where I can take my cousin for a good time on June 19th? \n",
      "\n",
      "102 2607 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33it [18:06, 32.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there a special event in Golden Gate Park for Mother's Day?\n",
      "62 2465 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34it [18:39, 32.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an astronomy enthusiast, where can I get the best experience of the Eta Aquarids meteor shower in 2024 in the Bay Area, and what should I expect?\n",
      "148 2514 243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [19:15, 33.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm new to exercising and looking to attend events to stay motivated. Are there any beginner-friendly events in the Bay Area coming up?\n",
      "136 2476 323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [19:48, 33.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recently heard about the Yerba Buena Gardens Festival 2024. Can you tell me what this event entails and if there are any free concerts? \n",
      "138 2654 256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [20:20, 33.00s/it]\n"
     ]
    }
   ],
   "source": [
    "for i,r in tqdm(raw_evals.iterrows()):\n",
    "    start = time.time()\n",
    "    q = r['Golden Question']\n",
    "    print(q)\n",
    "    rag_contexts = db.invoke(q)\n",
    "    rag_contexts = ' '.join([d.page_content for d in rag_contexts])\n",
    "    prompt = augment_prompt(q,rag_contexts)\n",
    "    input_len = len(prompt.split())\n",
    "    summarized_prompt = generate_response(f\"\"\"Summarize the text delimited by triple backticks \\ into a single sentence.```{prompt}```\"\"\")\n",
    "    print(len(q),len(prompt),len(summarized_prompt))\n",
    "    max_token_len = 1500-input_len-100 #100 buffer\n",
    "    start_time = time.time()\n",
    "    # while True: #while loop for token\n",
    "    answer = query({'inputs': f\"<s>[INST] {summarized_prompt} [/INST]\",\n",
    "                'parameters': {\"max_new_tokens\": max_token_len}})\n",
    "        # if 'error' not in answer:\n",
    "        #     break  #exit the while loop if there is no error\n",
    "        # max_token_len -= 100 #reduce by 100 in while loop\n",
    "        # print(f\"Failed to process prompt with token length: {max_token_len}\")\n",
    "        # if max_token_len <= 0:\n",
    "        #     break\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    answer = answer[0]['generated_text'].replace(f\"<s>[INST] {prompt} [/INST]\",\"\")\n",
    "    answer = answer.replace(\" . \",\". \").strip()\n",
    "\n",
    "    raw_evals.loc[i,'Llama QLORA RAG CRC GPT prompt summary Output'] = answer\n",
    "    raw_evals.loc[i,'Llama QLORA RAG CRC GPT prompt summary Output Time'] =  time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_evals.drop(['Mistral RAFT RAG CRC Output', 'Mistral RAFT RAG CRC Output Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_evals.to_csv(\"inferences_5_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Notes', 'Golden Question', 'Golden Answer', 'MPC',\n",
       "       'Llama QLORA Output', 'Llama QLORA Output Time',\n",
       "       'pretrained Mistral Output', 'pretrained Mistral Output Time',\n",
       "       'Mistral QLORA Output', 'Mistral QLORA Output Time',\n",
       "       'Llama RAFT Output', 'Llama RAFT Output Time', 'Mistral RAFT Output',\n",
       "       'Mistral RAFT Output Time', 'pretrained Llama Output',\n",
       "       'pretrained Llama Output Time', 'Llama_RAG_CRC', 'Llama_RAG_CRC_time',\n",
       "       'mistral_RAG_CRC', 'mistral_RAG_CRC_time', 'mistral_RAG_RR',\n",
       "       'mistral_RAG_RR_time', 'llama_RAG_RR', 'llama_RAG_RR_time',\n",
       "       'Llama RAFT RAG CRC Output', 'Llama RAFT RAG CRC Output Time',\n",
       "       'Mistral RAFT RAG CRC GPT prompt summary Output',\n",
       "       'Mistral RAFT RAG CRC GPT prompt summary Output Time',\n",
       "       'Mistral QLORA RAG CRC GPT prompt summary Output',\n",
       "       'Mistral QLORA RAG CRC GPT prompt summary Output Time',\n",
       "       'Llama QLORA RAG CRC GPT prompt summary Output',\n",
       "       'Llama QLORA RAG CRC GPT prompt summary Output Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_evals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Llama QLORA Output_conciseness_score</th>\n",
       "      <th>Llama QLORA Output_relevance_score</th>\n",
       "      <th>Llama QLORA Output_coherence_score</th>\n",
       "      <th>Llama QLORA Output_helpfulness_score</th>\n",
       "      <th>pretrained Mistral Output_conciseness_score</th>\n",
       "      <th>pretrained Mistral Output_relevance_score</th>\n",
       "      <th>pretrained Mistral Output_coherence_score</th>\n",
       "      <th>pretrained Mistral Output_helpfulness_score</th>\n",
       "      <th>Mistral QLORA Output_conciseness_score</th>\n",
       "      <th>Mistral QLORA Output_relevance_score</th>\n",
       "      <th>Mistral QLORA Output_coherence_score</th>\n",
       "      <th>Mistral QLORA Output_helpfulness_score</th>\n",
       "      <th>Llama RAFT Output_conciseness_score</th>\n",
       "      <th>Llama RAFT Output_relevance_score</th>\n",
       "      <th>Llama RAFT Output_coherence_score</th>\n",
       "      <th>Llama RAFT Output_helpfulness_score</th>\n",
       "      <th>Mistral RAFT Output_conciseness_score</th>\n",
       "      <th>Mistral RAFT Output_relevance_score</th>\n",
       "      <th>Mistral RAFT Output_coherence_score</th>\n",
       "      <th>Mistral RAFT Output_helpfulness_score</th>\n",
       "      <th>pretrained Llama Output_conciseness_score</th>\n",
       "      <th>pretrained Llama Output_relevance_score</th>\n",
       "      <th>pretrained Llama Output_coherence_score</th>\n",
       "      <th>pretrained Llama Output_helpfulness_score</th>\n",
       "      <th>Llama_RAG_CRC_conciseness_score</th>\n",
       "      <th>Llama_RAG_CRC_relevance_score</th>\n",
       "      <th>Llama_RAG_CRC_coherence_score</th>\n",
       "      <th>Llama_RAG_CRC_helpfulness_score</th>\n",
       "      <th>mistral_RAG_CRC_conciseness_score</th>\n",
       "      <th>mistral_RAG_CRC_relevance_score</th>\n",
       "      <th>mistral_RAG_CRC_coherence_score</th>\n",
       "      <th>mistral_RAG_CRC_helpfulness_score</th>\n",
       "      <th>mistral_RAG_RR_conciseness_score</th>\n",
       "      <th>mistral_RAG_RR_relevance_score</th>\n",
       "      <th>mistral_RAG_RR_coherence_score</th>\n",
       "      <th>mistral_RAG_RR_helpfulness_score</th>\n",
       "      <th>llama_RAG_RR_conciseness_score</th>\n",
       "      <th>llama_RAG_RR_relevance_score</th>\n",
       "      <th>llama_RAG_RR_coherence_score</th>\n",
       "      <th>llama_RAG_RR_helpfulness_score</th>\n",
       "      <th>Llama RAFT RAG CRC Output_conciseness_score</th>\n",
       "      <th>Llama RAFT RAG CRC Output_relevance_score</th>\n",
       "      <th>Llama RAFT RAG CRC Output_coherence_score</th>\n",
       "      <th>Llama RAFT RAG CRC Output_helpfulness_score</th>\n",
       "      <th>Mistral RAFT RAG CRC GPT prompt summary Output_conciseness_score</th>\n",
       "      <th>Mistral RAFT RAG CRC GPT prompt summary Output_relevance_score</th>\n",
       "      <th>Mistral RAFT RAG CRC GPT prompt summary Output_coherence_score</th>\n",
       "      <th>Mistral RAFT RAG CRC GPT prompt summary Output_helpfulness_score</th>\n",
       "      <th>Mistral QLORA RAG CRC GPT prompt summary Output_conciseness_score</th>\n",
       "      <th>Mistral QLORA RAG CRC GPT prompt summary Output_relevance_score</th>\n",
       "      <th>Mistral QLORA RAG CRC GPT prompt summary Output_coherence_score</th>\n",
       "      <th>Mistral QLORA RAG CRC GPT prompt summary Output_helpfulness_score</th>\n",
       "      <th>Llama QLORA RAG CRC GPT prompt summary Output_conciseness_score</th>\n",
       "      <th>Llama QLORA RAG CRC GPT prompt summary Output_relevance_score</th>\n",
       "      <th>Llama QLORA RAG CRC GPT prompt summary Output_coherence_score</th>\n",
       "      <th>Llama QLORA RAG CRC GPT prompt summary Output_helpfulness_score</th>\n",
       "      <th>GPT4_MQR_conciseness_score</th>\n",
       "      <th>GPT4_MQR_relevance_score</th>\n",
       "      <th>GPT4_MQR_coherence_score</th>\n",
       "      <th>GPT4_MQR_helpfulness_score</th>\n",
       "      <th>GPT4_conciseness_score</th>\n",
       "      <th>GPT4_relevance_score</th>\n",
       "      <th>GPT4_coherence_score</th>\n",
       "      <th>GPT4_helpfulness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What are your favorite luxury camp meals for a...</td>\n",
       "      <td>The text promotes joining the Funcheap email l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm taking a solo trip with my dog around Than...</td>\n",
       "      <td>The text provides information about DogFest 20...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm planning a 3-4 week family road trip from ...</td>\n",
       "      <td>The text includes information about two free e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What are the main differences between visiting...</td>\n",
       "      <td>The text discusses various popular events and ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Seeking destination and activity suggestions f...</td>\n",
       "      <td>The text is a list of different categories of ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           Question  \\\n",
       "0      0  What are your favorite luxury camp meals for a...   \n",
       "1      1  I'm taking a solo trip with my dog around Than...   \n",
       "2      2  I'm planning a 3-4 week family road trip from ...   \n",
       "3      3  What are the main differences between visiting...   \n",
       "4      4  Seeking destination and activity suggestions f...   \n",
       "\n",
       "                                             Context  \\\n",
       "0  The text promotes joining the Funcheap email l...   \n",
       "1  The text provides information about DogFest 20...   \n",
       "2  The text includes information about two free e...   \n",
       "3  The text discusses various popular events and ...   \n",
       "4  The text is a list of different categories of ...   \n",
       "\n",
       "   Llama QLORA Output_conciseness_score  Llama QLORA Output_relevance_score  \\\n",
       "0                                   0.0                                 0.0   \n",
       "1                                   0.0                                 0.0   \n",
       "2                                   0.0                                 0.0   \n",
       "3                                   0.0                                 0.0   \n",
       "4                                   0.0                                 0.0   \n",
       "\n",
       "   Llama QLORA Output_coherence_score  Llama QLORA Output_helpfulness_score  \\\n",
       "0                                 0.0                                   1.0   \n",
       "1                                 0.0                                   0.0   \n",
       "2                                 0.0                                   0.0   \n",
       "3                                 0.0                                   0.0   \n",
       "4                                 0.0                                   0.0   \n",
       "\n",
       "   pretrained Mistral Output_conciseness_score  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          1.0   \n",
       "\n",
       "   pretrained Mistral Output_relevance_score  \\\n",
       "0                                        0.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   pretrained Mistral Output_coherence_score  \\\n",
       "0                                        1.0   \n",
       "1                                        1.0   \n",
       "2                                        1.0   \n",
       "3                                        1.0   \n",
       "4                                        1.0   \n",
       "\n",
       "   pretrained Mistral Output_helpfulness_score  \\\n",
       "0                                          1.0   \n",
       "1                                          1.0   \n",
       "2                                          1.0   \n",
       "3                                          1.0   \n",
       "4                                          1.0   \n",
       "\n",
       "   Mistral QLORA Output_conciseness_score  \\\n",
       "0                                     0.0   \n",
       "1                                     1.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   Mistral QLORA Output_relevance_score  Mistral QLORA Output_coherence_score  \\\n",
       "0                                   0.0                                   1.0   \n",
       "1                                   0.0                                   0.0   \n",
       "2                                   0.0                                   0.0   \n",
       "3                                   0.0                                   0.0   \n",
       "4                                   0.0                                   0.0   \n",
       "\n",
       "   Mistral QLORA Output_helpfulness_score  \\\n",
       "0                                     1.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     1.0   \n",
       "\n",
       "   Llama RAFT Output_conciseness_score  Llama RAFT Output_relevance_score  \\\n",
       "0                                  0.0                                0.0   \n",
       "1                                  1.0                                1.0   \n",
       "2                                  0.0                                0.0   \n",
       "3                                  0.0                                0.0   \n",
       "4                                  0.0                                0.0   \n",
       "\n",
       "   Llama RAFT Output_coherence_score  Llama RAFT Output_helpfulness_score  \\\n",
       "0                                0.0                                  1.0   \n",
       "1                                0.0                                  0.0   \n",
       "2                                NaN                                  1.0   \n",
       "3                                0.0                                  0.0   \n",
       "4                                0.0                                  0.0   \n",
       "\n",
       "   Mistral RAFT Output_conciseness_score  Mistral RAFT Output_relevance_score  \\\n",
       "0                                    1.0                                  0.0   \n",
       "1                                    0.0                                  0.0   \n",
       "2                                    0.0                                  0.0   \n",
       "3                                    0.0                                  0.0   \n",
       "4                                    0.0                                  0.0   \n",
       "\n",
       "   Mistral RAFT Output_coherence_score  Mistral RAFT Output_helpfulness_score  \\\n",
       "0                                  0.0                                    1.0   \n",
       "1                                  1.0                                    1.0   \n",
       "2                                  1.0                                    1.0   \n",
       "3                                  1.0                                    1.0   \n",
       "4                                  0.0                                    1.0   \n",
       "\n",
       "   pretrained Llama Output_conciseness_score  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   pretrained Llama Output_relevance_score  \\\n",
       "0                                      0.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "\n",
       "   pretrained Llama Output_coherence_score  \\\n",
       "0                                      1.0   \n",
       "1                                      1.0   \n",
       "2                                      1.0   \n",
       "3                                      1.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   pretrained Llama Output_helpfulness_score  Llama_RAG_CRC_conciseness_score  \\\n",
       "0                                        1.0                              0.0   \n",
       "1                                        1.0                              0.0   \n",
       "2                                        1.0                              1.0   \n",
       "3                                        1.0                              0.0   \n",
       "4                                        1.0                              1.0   \n",
       "\n",
       "   Llama_RAG_CRC_relevance_score  Llama_RAG_CRC_coherence_score  \\\n",
       "0                            0.0                            1.0   \n",
       "1                            1.0                            1.0   \n",
       "2                            1.0                            0.0   \n",
       "3                            0.0                            1.0   \n",
       "4                            0.0                            1.0   \n",
       "\n",
       "   Llama_RAG_CRC_helpfulness_score  mistral_RAG_CRC_conciseness_score  \\\n",
       "0                              1.0                                0.0   \n",
       "1                              1.0                                0.0   \n",
       "2                              1.0                                0.0   \n",
       "3                              1.0                                0.0   \n",
       "4                              1.0                                0.0   \n",
       "\n",
       "   mistral_RAG_CRC_relevance_score  mistral_RAG_CRC_coherence_score  \\\n",
       "0                              0.0                              1.0   \n",
       "1                              0.0                              1.0   \n",
       "2                              0.0                              0.0   \n",
       "3                              0.0                              1.0   \n",
       "4                              0.0                              1.0   \n",
       "\n",
       "   mistral_RAG_CRC_helpfulness_score  mistral_RAG_RR_conciseness_score  \\\n",
       "0                                1.0                               0.0   \n",
       "1                                1.0                               0.0   \n",
       "2                                0.0                               0.0   \n",
       "3                                1.0                               0.0   \n",
       "4                                1.0                               0.0   \n",
       "\n",
       "   mistral_RAG_RR_relevance_score  mistral_RAG_RR_coherence_score  \\\n",
       "0                             0.0                             1.0   \n",
       "1                             1.0                             1.0   \n",
       "2                             1.0                             1.0   \n",
       "3                             0.0                             1.0   \n",
       "4                             0.0                             1.0   \n",
       "\n",
       "   mistral_RAG_RR_helpfulness_score  llama_RAG_RR_conciseness_score  \\\n",
       "0                               1.0                             0.0   \n",
       "1                               1.0                             0.0   \n",
       "2                               1.0                             1.0   \n",
       "3                               1.0                             0.0   \n",
       "4                               1.0                             0.0   \n",
       "\n",
       "   llama_RAG_RR_relevance_score  llama_RAG_RR_coherence_score  \\\n",
       "0                           0.0                           1.0   \n",
       "1                           0.0                           1.0   \n",
       "2                           1.0                           1.0   \n",
       "3                           0.0                           1.0   \n",
       "4                           0.0                           1.0   \n",
       "\n",
       "   llama_RAG_RR_helpfulness_score  \\\n",
       "0                             1.0   \n",
       "1                             1.0   \n",
       "2                             1.0   \n",
       "3                             1.0   \n",
       "4                             1.0   \n",
       "\n",
       "   Llama RAFT RAG CRC Output_conciseness_score  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   Llama RAFT RAG CRC Output_relevance_score  \\\n",
       "0                                        1.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   Llama RAFT RAG CRC Output_coherence_score  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   Llama RAFT RAG CRC Output_helpfulness_score  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   Mistral RAFT RAG CRC GPT prompt summary Output_conciseness_score  \\\n",
       "0                                                0.0                  \n",
       "1                                                0.0                  \n",
       "2                                                0.0                  \n",
       "3                                                0.0                  \n",
       "4                                                0.0                  \n",
       "\n",
       "   Mistral RAFT RAG CRC GPT prompt summary Output_relevance_score  \\\n",
       "0                                                0.0                \n",
       "1                                                1.0                \n",
       "2                                                1.0                \n",
       "3                                                0.0                \n",
       "4                                                0.0                \n",
       "\n",
       "   Mistral RAFT RAG CRC GPT prompt summary Output_coherence_score  \\\n",
       "0                                                1.0                \n",
       "1                                                1.0                \n",
       "2                                                0.0                \n",
       "3                                                1.0                \n",
       "4                                                0.0                \n",
       "\n",
       "   Mistral RAFT RAG CRC GPT prompt summary Output_helpfulness_score  \\\n",
       "0                                                1.0                  \n",
       "1                                                1.0                  \n",
       "2                                                0.0                  \n",
       "3                                                1.0                  \n",
       "4                                                0.0                  \n",
       "\n",
       "   Mistral QLORA RAG CRC GPT prompt summary Output_conciseness_score  \\\n",
       "0                                                1.0                   \n",
       "1                                                1.0                   \n",
       "2                                                0.0                   \n",
       "3                                                0.0                   \n",
       "4                                                1.0                   \n",
       "\n",
       "   Mistral QLORA RAG CRC GPT prompt summary Output_relevance_score  \\\n",
       "0                                                0.0                 \n",
       "1                                                1.0                 \n",
       "2                                                1.0                 \n",
       "3                                                0.0                 \n",
       "4                                                1.0                 \n",
       "\n",
       "   Mistral QLORA RAG CRC GPT prompt summary Output_coherence_score  \\\n",
       "0                                                0.0                 \n",
       "1                                                1.0                 \n",
       "2                                                0.0                 \n",
       "3                                                0.0                 \n",
       "4                                                1.0                 \n",
       "\n",
       "   Mistral QLORA RAG CRC GPT prompt summary Output_helpfulness_score  \\\n",
       "0                                                1.0                   \n",
       "1                                                1.0                   \n",
       "2                                                0.0                   \n",
       "3                                                1.0                   \n",
       "4                                                1.0                   \n",
       "\n",
       "   Llama QLORA RAG CRC GPT prompt summary Output_conciseness_score  \\\n",
       "0                                                0.0                 \n",
       "1                                                0.0                 \n",
       "2                                                0.0                 \n",
       "3                                                0.0                 \n",
       "4                                                1.0                 \n",
       "\n",
       "   Llama QLORA RAG CRC GPT prompt summary Output_relevance_score  \\\n",
       "0                                                0.0               \n",
       "1                                                1.0               \n",
       "2                                                1.0               \n",
       "3                                                0.0               \n",
       "4                                                1.0               \n",
       "\n",
       "   Llama QLORA RAG CRC GPT prompt summary Output_coherence_score  \\\n",
       "0                                                0.0               \n",
       "1                                                1.0               \n",
       "2                                                0.0               \n",
       "3                                                0.0               \n",
       "4                                                1.0               \n",
       "\n",
       "   Llama QLORA RAG CRC GPT prompt summary Output_helpfulness_score  \\\n",
       "0                                                0.0                 \n",
       "1                                                0.0                 \n",
       "2                                                0.0                 \n",
       "3                                                1.0                 \n",
       "4                                                1.0                 \n",
       "\n",
       "   GPT4_MQR_conciseness_score  GPT4_MQR_relevance_score  \\\n",
       "0                         1.0                       1.0   \n",
       "1                         1.0                       0.0   \n",
       "2                         1.0                       1.0   \n",
       "3                         1.0                       0.0   \n",
       "4                         1.0                       0.0   \n",
       "\n",
       "   GPT4_MQR_coherence_score  GPT4_MQR_helpfulness_score  \\\n",
       "0                       0.0                         0.0   \n",
       "1                       1.0                         0.0   \n",
       "2                       1.0                         0.0   \n",
       "3                       1.0                         0.0   \n",
       "4                       1.0                         0.0   \n",
       "\n",
       "   GPT4_conciseness_score  GPT4_relevance_score  GPT4_coherence_score  \\\n",
       "0                     0.0                   0.0                   1.0   \n",
       "1                     1.0                   1.0                   1.0   \n",
       "2                     0.0                   1.0                   1.0   \n",
       "3                     1.0                   0.0                   1.0   \n",
       "4                     1.0                   0.0                   1.0   \n",
       "\n",
       "   GPT4_helpfulness_score  \n",
       "0                     1.0  \n",
       "1                     1.0  \n",
       "2                     1.0  \n",
       "3                     1.0  \n",
       "4                     1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit = pd.read_csv(\"criteria_res_27.csv\",index_col=\"Unnamed: 0\").reset_index()\n",
    "crit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Llama QLORA Output_conciseness_score',\n",
       " 'Llama QLORA Output_relevance_score',\n",
       " 'Llama QLORA Output_coherence_score',\n",
       " 'Llama QLORA Output_helpfulness_score',\n",
       " 'pretrained Mistral Output_conciseness_score',\n",
       " 'pretrained Mistral Output_relevance_score',\n",
       " 'pretrained Mistral Output_coherence_score',\n",
       " 'pretrained Mistral Output_helpfulness_score',\n",
       " 'Mistral QLORA Output_conciseness_score',\n",
       " 'Mistral QLORA Output_relevance_score',\n",
       " 'Mistral QLORA Output_coherence_score',\n",
       " 'Mistral QLORA Output_helpfulness_score',\n",
       " 'Llama RAFT Output_conciseness_score',\n",
       " 'Llama RAFT Output_relevance_score',\n",
       " 'Llama RAFT Output_coherence_score',\n",
       " 'Llama RAFT Output_helpfulness_score',\n",
       " 'Mistral RAFT Output_conciseness_score',\n",
       " 'Mistral RAFT Output_relevance_score',\n",
       " 'Mistral RAFT Output_coherence_score',\n",
       " 'Mistral RAFT Output_helpfulness_score',\n",
       " 'pretrained Llama Output_conciseness_score',\n",
       " 'pretrained Llama Output_relevance_score',\n",
       " 'pretrained Llama Output_coherence_score',\n",
       " 'pretrained Llama Output_helpfulness_score',\n",
       " 'Llama_RAG_CRC_conciseness_score',\n",
       " 'Llama_RAG_CRC_relevance_score',\n",
       " 'Llama_RAG_CRC_coherence_score',\n",
       " 'Llama_RAG_CRC_helpfulness_score',\n",
       " 'mistral_RAG_CRC_conciseness_score',\n",
       " 'mistral_RAG_CRC_relevance_score',\n",
       " 'mistral_RAG_CRC_coherence_score',\n",
       " 'mistral_RAG_CRC_helpfulness_score',\n",
       " 'mistral_RAG_RR_conciseness_score',\n",
       " 'mistral_RAG_RR_relevance_score',\n",
       " 'mistral_RAG_RR_coherence_score',\n",
       " 'mistral_RAG_RR_helpfulness_score',\n",
       " 'llama_RAG_RR_conciseness_score',\n",
       " 'llama_RAG_RR_relevance_score',\n",
       " 'llama_RAG_RR_coherence_score',\n",
       " 'llama_RAG_RR_helpfulness_score',\n",
       " 'Llama RAFT RAG CRC Output_conciseness_score',\n",
       " 'Llama RAFT RAG CRC Output_relevance_score',\n",
       " 'Llama RAFT RAG CRC Output_coherence_score',\n",
       " 'Llama RAFT RAG CRC Output_helpfulness_score',\n",
       " 'Mistral RAFT RAG CRC GPT prompt summary Output_conciseness_score',\n",
       " 'Mistral RAFT RAG CRC GPT prompt summary Output_relevance_score',\n",
       " 'Mistral RAFT RAG CRC GPT prompt summary Output_coherence_score',\n",
       " 'Mistral RAFT RAG CRC GPT prompt summary Output_helpfulness_score',\n",
       " 'Mistral QLORA RAG CRC GPT prompt summary Output_conciseness_score',\n",
       " 'Mistral QLORA RAG CRC GPT prompt summary Output_relevance_score',\n",
       " 'Mistral QLORA RAG CRC GPT prompt summary Output_coherence_score',\n",
       " 'Mistral QLORA RAG CRC GPT prompt summary Output_helpfulness_score',\n",
       " 'Llama QLORA RAG CRC GPT prompt summary Output_conciseness_score',\n",
       " 'Llama QLORA RAG CRC GPT prompt summary Output_relevance_score',\n",
       " 'Llama QLORA RAG CRC GPT prompt summary Output_coherence_score',\n",
       " 'Llama QLORA RAG CRC GPT prompt summary Output_helpfulness_score',\n",
       " 'GPT4_MQR_conciseness_score',\n",
       " 'GPT4_MQR_relevance_score',\n",
       " 'GPT4_MQR_coherence_score',\n",
       " 'GPT4_MQR_helpfulness_score',\n",
       " 'GPT4_conciseness_score',\n",
       " 'GPT4_relevance_score',\n",
       " 'GPT4_coherence_score',\n",
       " 'GPT4_helpfulness_score']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in crit.columns if 'score' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Llama QLORA Output_conciseness_score</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Llama QLORA</td>\n",
       "      <td>conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Llama QLORA Output_conciseness_score</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Llama QLORA</td>\n",
       "      <td>conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Llama QLORA Output_conciseness_score</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Llama QLORA</td>\n",
       "      <td>conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Llama QLORA Output_conciseness_score</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Llama QLORA</td>\n",
       "      <td>conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Llama QLORA Output_conciseness_score</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Llama QLORA</td>\n",
       "      <td>conciseness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>23</td>\n",
       "      <td>GPT4_helpfulness_score</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>helpfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>24</td>\n",
       "      <td>GPT4_helpfulness_score</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>helpfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>25</td>\n",
       "      <td>GPT4_helpfulness_score</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>helpfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>26</td>\n",
       "      <td>GPT4_helpfulness_score</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>helpfulness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>27</td>\n",
       "      <td>GPT4_helpfulness_score</td>\n",
       "      <td>1.0</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>helpfulness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1789 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                              variable  value        model  \\\n",
       "0         0  Llama QLORA Output_conciseness_score    0.0  Llama QLORA   \n",
       "1         1  Llama QLORA Output_conciseness_score    0.0  Llama QLORA   \n",
       "2         2  Llama QLORA Output_conciseness_score    0.0  Llama QLORA   \n",
       "3         3  Llama QLORA Output_conciseness_score    0.0  Llama QLORA   \n",
       "4         4  Llama QLORA Output_conciseness_score    0.0  Llama QLORA   \n",
       "...     ...                                   ...    ...          ...   \n",
       "2354     23                GPT4_helpfulness_score    1.0         GPT4   \n",
       "2355     24                GPT4_helpfulness_score    1.0         GPT4   \n",
       "2356     25                GPT4_helpfulness_score    1.0         GPT4   \n",
       "2357     26                GPT4_helpfulness_score    1.0         GPT4   \n",
       "2358     27                GPT4_helpfulness_score    1.0         GPT4   \n",
       "\n",
       "           metric  \n",
       "0     conciseness  \n",
       "1     conciseness  \n",
       "2     conciseness  \n",
       "3     conciseness  \n",
       "4     conciseness  \n",
       "...           ...  \n",
       "2354  helpfulness  \n",
       "2355  helpfulness  \n",
       "2356  helpfulness  \n",
       "2357  helpfulness  \n",
       "2358  helpfulness  \n",
       "\n",
       "[1789 rows x 5 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit_melt = pd.melt(crit, id_vars='index', value_vars=[c for c in crit.columns if 'score' in c]).dropna()\n",
    "crit_melt['model'] = crit_melt['variable'].apply(lambda x:' '.join(x.replace('_score','').split('_')[:-1]).replace('Output','').replace(' GPT prompt summary ','').strip())\n",
    "crit_melt['metric'] = crit_melt['variable'].apply(lambda x:x.rsplit('_')[-2])\n",
    "\n",
    "crit_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_melt_df = crit_melt.groupby(['metric','model'])['value'].mean().to_frame('score').unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8b664_row0_col2, #T_8b664_row1_col1, #T_8b664_row1_col3, #T_8b664_row14_col0, #T_8b664_row14_col2 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8b664\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >metric</th>\n",
       "      <th id=\"T_8b664_level0_col0\" class=\"col_heading level0 col0\" >coherence</th>\n",
       "      <th id=\"T_8b664_level0_col1\" class=\"col_heading level0 col1\" >conciseness</th>\n",
       "      <th id=\"T_8b664_level0_col2\" class=\"col_heading level0 col2\" >helpfulness</th>\n",
       "      <th id=\"T_8b664_level0_col3\" class=\"col_heading level0 col3\" >relevance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >&nbsp;</th>\n",
       "      <th class=\"index_name level1\" >model</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"16\">score</th>\n",
       "      <th id=\"T_8b664_level1_row0\" class=\"row_heading level1 row0\" >GPT4</th>\n",
       "      <td id=\"T_8b664_row0_col0\" class=\"data row0 col0\" >0.892857</td>\n",
       "      <td id=\"T_8b664_row0_col1\" class=\"data row0 col1\" >0.714286</td>\n",
       "      <td id=\"T_8b664_row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "      <td id=\"T_8b664_row0_col3\" class=\"data row0 col3\" >0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row1\" class=\"row_heading level1 row1\" >GPT4 MQR</th>\n",
       "      <td id=\"T_8b664_row1_col0\" class=\"data row1 col0\" >0.964286</td>\n",
       "      <td id=\"T_8b664_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_8b664_row1_col2\" class=\"data row1 col2\" >0.357143</td>\n",
       "      <td id=\"T_8b664_row1_col3\" class=\"data row1 col3\" >0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row2\" class=\"row_heading level1 row2\" >Llama QLORA</th>\n",
       "      <td id=\"T_8b664_row2_col0\" class=\"data row2 col0\" >0.214286</td>\n",
       "      <td id=\"T_8b664_row2_col1\" class=\"data row2 col1\" >0.142857</td>\n",
       "      <td id=\"T_8b664_row2_col2\" class=\"data row2 col2\" >0.464286</td>\n",
       "      <td id=\"T_8b664_row2_col3\" class=\"data row2 col3\" >0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row3\" class=\"row_heading level1 row3\" >Llama QLORA RAG CRC</th>\n",
       "      <td id=\"T_8b664_row3_col0\" class=\"data row3 col0\" >0.107143</td>\n",
       "      <td id=\"T_8b664_row3_col1\" class=\"data row3 col1\" >0.107143</td>\n",
       "      <td id=\"T_8b664_row3_col2\" class=\"data row3 col2\" >0.464286</td>\n",
       "      <td id=\"T_8b664_row3_col3\" class=\"data row3 col3\" >0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row4\" class=\"row_heading level1 row4\" >Llama RAFT</th>\n",
       "      <td id=\"T_8b664_row4_col0\" class=\"data row4 col0\" >0.444444</td>\n",
       "      <td id=\"T_8b664_row4_col1\" class=\"data row4 col1\" >0.250000</td>\n",
       "      <td id=\"T_8b664_row4_col2\" class=\"data row4 col2\" >0.678571</td>\n",
       "      <td id=\"T_8b664_row4_col3\" class=\"data row4 col3\" >0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row5\" class=\"row_heading level1 row5\" >Llama RAFT RAG CRC</th>\n",
       "      <td id=\"T_8b664_row5_col0\" class=\"data row5 col0\" >0.464286</td>\n",
       "      <td id=\"T_8b664_row5_col1\" class=\"data row5 col1\" >0.035714</td>\n",
       "      <td id=\"T_8b664_row5_col2\" class=\"data row5 col2\" >0.500000</td>\n",
       "      <td id=\"T_8b664_row5_col3\" class=\"data row5 col3\" >0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row6\" class=\"row_heading level1 row6\" >Llama RAG CRC</th>\n",
       "      <td id=\"T_8b664_row6_col0\" class=\"data row6 col0\" >0.571429</td>\n",
       "      <td id=\"T_8b664_row6_col1\" class=\"data row6 col1\" >0.214286</td>\n",
       "      <td id=\"T_8b664_row6_col2\" class=\"data row6 col2\" >0.892857</td>\n",
       "      <td id=\"T_8b664_row6_col3\" class=\"data row6 col3\" >0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row7\" class=\"row_heading level1 row7\" >Mistral QLORA</th>\n",
       "      <td id=\"T_8b664_row7_col0\" class=\"data row7 col0\" >0.250000</td>\n",
       "      <td id=\"T_8b664_row7_col1\" class=\"data row7 col1\" >0.214286</td>\n",
       "      <td id=\"T_8b664_row7_col2\" class=\"data row7 col2\" >0.428571</td>\n",
       "      <td id=\"T_8b664_row7_col3\" class=\"data row7 col3\" >0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row8\" class=\"row_heading level1 row8\" >Mistral QLORA RAG CRC</th>\n",
       "      <td id=\"T_8b664_row8_col0\" class=\"data row8 col0\" >0.142857</td>\n",
       "      <td id=\"T_8b664_row8_col1\" class=\"data row8 col1\" >0.214286</td>\n",
       "      <td id=\"T_8b664_row8_col2\" class=\"data row8 col2\" >0.357143</td>\n",
       "      <td id=\"T_8b664_row8_col3\" class=\"data row8 col3\" >0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row9\" class=\"row_heading level1 row9\" >Mistral RAFT</th>\n",
       "      <td id=\"T_8b664_row9_col0\" class=\"data row9 col0\" >0.714286</td>\n",
       "      <td id=\"T_8b664_row9_col1\" class=\"data row9 col1\" >0.250000</td>\n",
       "      <td id=\"T_8b664_row9_col2\" class=\"data row9 col2\" >0.928571</td>\n",
       "      <td id=\"T_8b664_row9_col3\" class=\"data row9 col3\" >0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row10\" class=\"row_heading level1 row10\" >Mistral RAFT RAG CRC</th>\n",
       "      <td id=\"T_8b664_row10_col0\" class=\"data row10 col0\" >0.428571</td>\n",
       "      <td id=\"T_8b664_row10_col1\" class=\"data row10 col1\" >0.000000</td>\n",
       "      <td id=\"T_8b664_row10_col2\" class=\"data row10 col2\" >0.428571</td>\n",
       "      <td id=\"T_8b664_row10_col3\" class=\"data row10 col3\" >0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row11\" class=\"row_heading level1 row11\" >llama RAG RR</th>\n",
       "      <td id=\"T_8b664_row11_col0\" class=\"data row11 col0\" >0.607143</td>\n",
       "      <td id=\"T_8b664_row11_col1\" class=\"data row11 col1\" >0.071429</td>\n",
       "      <td id=\"T_8b664_row11_col2\" class=\"data row11 col2\" >0.814815</td>\n",
       "      <td id=\"T_8b664_row11_col3\" class=\"data row11 col3\" >0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row12\" class=\"row_heading level1 row12\" >mistral RAG CRC</th>\n",
       "      <td id=\"T_8b664_row12_col0\" class=\"data row12 col0\" >0.821429</td>\n",
       "      <td id=\"T_8b664_row12_col1\" class=\"data row12 col1\" >0.142857</td>\n",
       "      <td id=\"T_8b664_row12_col2\" class=\"data row12 col2\" >0.785714</td>\n",
       "      <td id=\"T_8b664_row12_col3\" class=\"data row12 col3\" >0.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row13\" class=\"row_heading level1 row13\" >mistral RAG RR</th>\n",
       "      <td id=\"T_8b664_row13_col0\" class=\"data row13 col0\" >0.592593</td>\n",
       "      <td id=\"T_8b664_row13_col1\" class=\"data row13 col1\" >0.035714</td>\n",
       "      <td id=\"T_8b664_row13_col2\" class=\"data row13 col2\" >0.964286</td>\n",
       "      <td id=\"T_8b664_row13_col3\" class=\"data row13 col3\" >0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row14\" class=\"row_heading level1 row14\" >pretrained Llama</th>\n",
       "      <td id=\"T_8b664_row14_col0\" class=\"data row14 col0\" >1.000000</td>\n",
       "      <td id=\"T_8b664_row14_col1\" class=\"data row14 col1\" >0.142857</td>\n",
       "      <td id=\"T_8b664_row14_col2\" class=\"data row14 col2\" >1.000000</td>\n",
       "      <td id=\"T_8b664_row14_col3\" class=\"data row14 col3\" >0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8b664_level1_row15\" class=\"row_heading level1 row15\" >pretrained Mistral</th>\n",
       "      <td id=\"T_8b664_row15_col0\" class=\"data row15 col0\" >0.821429</td>\n",
       "      <td id=\"T_8b664_row15_col1\" class=\"data row15 col1\" >0.178571</td>\n",
       "      <td id=\"T_8b664_row15_col2\" class=\"data row15 col2\" >0.928571</td>\n",
       "      <td id=\"T_8b664_row15_col3\" class=\"data row15 col3\" >0.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b9c0e1a0>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crit_melt_df.T.style.apply(highlight_max,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
